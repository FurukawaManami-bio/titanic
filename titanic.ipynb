{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import torch.quantization\n",
    "\n",
    "train_df = pd.read_csv('/home/manami_furukawa/taitanic/train.csv')\n",
    "test_df = pd.read_csv('/home/manami_furukawa/taitanic/test.csv')\n",
    "\n",
    "all_df = pd.concat([train_df, test_df],sort=False).reset_index(drop=True)\n",
    "\n",
    "#敬称で年齢の欠損値を埋める\n",
    "#name_df = all_df[\"Name\"].str.split(\"[,.]\",2,expand=True)\n",
    "\n",
    "name_df = all_df[\"Name\"].str.split(\",\",expand=True)\n",
    "#print(name_df)\n",
    "name_df = name_df[1].str.split(\".\",expand=True)\n",
    "#print(name_df)\n",
    "\n",
    "name_df.columns = [\"family_name\",\"honorific\",\"name\"]\n",
    "\n",
    "name_df[\"family_name\"] =name_df[\"family_name\"].str.strip()\n",
    "name_df[\"honorific\"] =name_df[\"honorific\"].str.strip()\n",
    "name_df[\"name\"] =name_df[\"name\"].str.strip()\n",
    "\n",
    "all_df = pd.concat([all_df, name_df], axis=1)\n",
    "\n",
    "all_df[[\"Age\",\"honorific\"]].groupby(\"honorific\").mean()\n",
    "\n",
    "#苗字敬称のデータを加える\n",
    "train_df = pd.concat([train_df,name_df[0:len(train_df)].reset_index(drop=True)],axis=1)\n",
    "test_df = pd.concat([test_df,name_df[0:len(test_df)].reset_index(drop=True)],axis=1)\n",
    "#敬称ごとの年齢の平均\n",
    "honorific_age_mean_train = train_df[[\"honorific\",\"Age\"]].groupby(\"honorific\").mean().reset_index()\n",
    "honorific_age_mean_test = test_df[[\"honorific\",\"Age\"]].groupby(\"honorific\").mean().reset_index()\n",
    "\n",
    "honorific_age_mean_train.columns = [\"honorific\",\"honorific_Age\"]\n",
    "honorific_age_mean_test.columns = [\"honorific\",\"honorific_Age\"]\n",
    "\n",
    "#元のデータにマージ\n",
    "train_df = pd.merge(train_df, honorific_age_mean_train, on=\"honorific\", how=\"left\")\n",
    "test_df = pd.merge(test_df, honorific_age_mean_test, on=\"honorific\", how=\"left\")\n",
    "#訓練ようのデータの欠損値に年齢の平均値を入れる\n",
    "train_df.loc[(train_df[\"Age\"].isnull()), \"Age\"] = train_df[\"honorific_Age\"]\n",
    "test_df.loc[(test_df[\"Age\"].isnull()), \"Age\"] = test_df[\"honorific_Age\"]\n",
    "\n",
    "#honolific_ageを消す\n",
    "train_df = train_df.drop([\"honorific_Age\"],axis=1)\n",
    "test_df = test_df.drop([\"honorific_Age\"],axis=1)\n",
    "\n",
    "#敬称の整理\n",
    "train_df.loc[~((train_df[\"honorific\"] ==\"Mr\") |\n",
    "    (train_df[\"honorific\"] ==\"Miss\") |\n",
    "    (train_df[\"honorific\"] ==\"Mrs\") |\n",
    "    (train_df[\"honorific\"] ==\"Master\")), \"honorific\"] = \"other\"\n",
    "\n",
    "test_df.loc[~((test_df[\"honorific\"] ==\"Mr\") |\n",
    "    (test_df[\"honorific\"] ==\"Miss\") |\n",
    "    (test_df[\"honorific\"] ==\"Mrs\") |\n",
    "    (test_df[\"honorific\"] ==\"Master\")), \"honorific\"] = \"other\"\n",
    "\n",
    "#print(train_df.columns)\n",
    "\n",
    "\n",
    "def process_df(df):\n",
    "    df = df.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\",\"Embarked\",\"family_name\",\"name\",\"honorific\"], axis=1)\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\n",
    "    #df = df.replace(\"Miss\", 0)\n",
    "    #df = df.replace(\"Mrs\", 1)\n",
    "    #df = df.replace(\"Master\", 2)\n",
    "    #df = df.replace(\"Mr\", 3)\n",
    "    #df = df.replace(\"other\", 4)\n",
    "    df = df.replace(\"male\", 0)\n",
    "    df = df.replace(\"female\", 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = process_df(train_df)\n",
    "test_df = process_df(test_df)\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.X = self.df.drop([\"Survived\"], axis=1)\n",
    "        self.Y = self.df[\"Survived\"]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Convert to numpy array or tensor\n",
    "        return self.X.iloc[idx,:].values, self.Y.iloc[idx]\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = Dataset(train_df)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_sz, out_sz):\n",
    "        super(Net, self).__init__()\n",
    "        self.f1 = nn.Linear(input_sz, hidden_sz)\n",
    "        self.f2 = nn.Linear(hidden_sz, out_sz)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = F.sigmoid(self.f1(x))\n",
    "        y = self.f2(h1)\n",
    "\n",
    "        return y\n",
    "\n",
    "input_sz = 6\n",
    "hidden_sz = 3\n",
    "out_sz = 2\n",
    "net = Net(input_sz, hidden_sz, out_sz)\n",
    "\n",
    "learning_rate = 0.01\n",
    "loss_func = nn.MSELoss(reduction=\"sum\")\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "epoch = 32\n",
    "\n",
    "def convert_label_to_onehot(labels):\n",
    "    onehot = np.zeros((len(labels), labels.max().item()+1))\n",
    "    idx = [(i, t.item()) for i, t in enumerate(labels)]\n",
    "    for i, label in idx:\n",
    "        onehot[i, label] = 1\n",
    "    # Convert to float tensor\n",
    "    return torch.from_numpy(onehot).float()\n",
    "\n",
    "def train():\n",
    "    for e in range(epoch):\n",
    "        for X, labels in train_dataloader:\n",
    "            T = convert_label_to_onehot(labels)\n",
    "            y = net(X.float())\n",
    "            # Use Torch.Tensor(T) instead of Torch.FloatTensor(T)\n",
    "            loss = loss_func(y, torch.Tensor(T))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "train()\n",
    "\n",
    "def test():\n",
    "    test_X = torch.tensor(test_df.iloc[:,:].values)\n",
    "    test_Y = net(test_X.float())\n",
    "    survived = torch.max(test_Y, dim=1)[1]\n",
    "    test_paID = pd.read_csv('/home/manami_furukawa/taitanic/gender_submission.csv')['PassengerId']\n",
    "    sub_df = pd.DataFrame({\"PassengerId\":test_paID.values, \"Survived\":survived})\n",
    "    print(sub_df)\n",
    "    return sub_df\n",
    "\n",
    "#print(train_df.columns)\n",
    "sub_df = test()\n",
    "sub_df.to_csv(\"./submission.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
